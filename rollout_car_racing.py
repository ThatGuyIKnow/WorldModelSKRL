import os
import gymnasium as gym
import numpy as np
from PIL import Image
import csv
from tqdm import tqdm
import multiprocessing

def run_worker(env_name, worker_id, output_folder, total_steps=1000, max_eps_length=50, env_kwargs={}, repeat_action=1, frame_skip=4, skip_first=0):
    """
    Worker function to simulate a gym environment for a specified number of steps, save each frame as an image, 
    and record details (reward, done, action, image paths) in a CSV file.

    Parameters:
    env_name (str): The name of the gym environment to simulate.
    output_folder (str): The directory where the images and CSV will be saved.
    total_steps (int): The total number of steps to simulate across all episodes.
    """
    # Initialize the environment
    env = gym.make(env_name, render_mode='rgb_array', **env_kwargs)

    # Ensure the output directory exists
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    csv_file_path = os.path.join(output_folder, 'details_simulation.csv')
    with open(csv_file_path, 'w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['Episode', 'Step', 'Action', 'Reward', 'Done', 'Truncated', 'ImagePath', 'NextImagePath', 'Worker'])

    step_count = 0
    episode = 0
    pbar = tqdm(total=total_steps, position=worker_id, leave=True)
    while step_count < total_steps:
        observation = env.reset()
        eps_length = 0
        last_img_path = None
        
        for _ in range(skip_first):
            action = env.action_space.sample() * 0
            observation, reward, done, truncated, info = env.step(action)


        action = env.action_space.sample()
        for step in range(total_steps):

            if step % repeat_action == 0:
                action = env.action_space.sample()
            if step % frame_skip == 0:
                # Render the environment to a numpy array and save as an image
                frame = env.render()
                img_path = os.path.join(output_folder, f'episode_{episode}_step_{step}.png')
                Image.fromarray(frame).save(img_path)

                observation, reward, done, truncated, info = env.step(action)
            
                truncated |= eps_length > max_eps_length

                # Prepare next image path for CSV (None if simulation ends)
                next_img_path = os.path.join(output_folder, f'episode_{episode}_step_{step+frame_skip}.png')

                # Write details to CSV
                with open(csv_file_path, 'a', newline='') as file:
                    writer = csv.writer(file)
                    writer.writerow([episode, step, action, reward, done, truncated, img_path, next_img_path, worker_id])

                last_img_path = img_path
                step_count += 1
                eps_length += 1

                pbar.update(1)
                if done or step_count >= total_steps or eps_length > max_eps_length:
                    frame = env.render()
                    Image.fromarray(frame).save(next_img_path)
                    break
            else:
                observation, reward, done, truncated, info = env.step(action)
            
                truncated |= eps_length > max_eps_length

                step_count += 1
                eps_length += 1

                pbar.update(1)
        episode += 1
    pbar.close()
    env.close()

def run_workers(num_workers, env_name, output_folder, total_steps=1000, max_eps_length=50, env_kwargs={}, repeat_action=200, frame_skip=4, skip_first=0):
    """
    Function to run multiple workers simultaneously.

    Parameters:
    num_workers (int): The number of worker processes to run.
    """
    processes = []
    for i in range(num_workers):
        process = multiprocessing.Process(target=run_worker, args=(env_name, i, os.path.join(output_folder, f'worker_{i}'), total_steps, max_eps_length, env_kwargs, repeat_action, frame_skip, skip_first))
        process.start()
        processes.append(process)
    for process in processes:
        process.join()

def collate_csv(output_folder, num_workers):
    """
    Function to collate CSV files generated by worker processes into a single main CSV file.

    Parameters:
    output_folder (str): The directory containing the CSV files generated by workers.
    num_workers (int): The number of worker processes.
    """
    main_csv_file_path = os.path.join(output_folder, 'main_details_simulation.csv')
    with open(main_csv_file_path, 'w', newline='') as main_file:
        writer = csv.writer(main_file)
        writer.writerow(['Episode', 'Step', 'Action', 'Reward', 'Done', 'Truncated', 'ImagePath', 'NextImagePath', 'Worker'])
        for i in range(num_workers):
            worker_csv_file_path = os.path.join(output_folder, f'worker_{i}', 'details_simulation.csv')
            with open(worker_csv_file_path, 'r') as worker_file:
                reader = csv.reader(worker_file)
                next(reader)  # Skip header
                for row in reader:
                    writer.writerow(row)

# Example usage
run_workers(
    num_workers=8, 
    env_name='CarRacing-v2', 
    output_folder='./data/carracing-v2', 
    total_steps=int(1e6/8), 
    max_eps_length=1000, 
    skip_first=50,
    repeat_action=4,
    frame_skip=4
)
collate_csv('./data/carracing-v2', num_workers=8)
